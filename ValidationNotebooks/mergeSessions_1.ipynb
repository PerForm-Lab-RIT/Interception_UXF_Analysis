{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Modules/\")\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "    \n",
    "import logging\n",
    "\n",
    "#fmt = 'logging.Formatter(''%(levelname)s_%(name)s-%(funcName)s(): - %(message)s'\n",
    "fmt = '%(levelname)s_%(name)s-%(funcName)s(): - %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=fmt)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['subID', 'trialInfo', 'expConfig', 'rawExpUnity', 'rawExpGaze', 'processedExp', 'rawCalibUnity', 'rawCalibGaze', 'processedCalib', 'analysisParameters', 'fixAssessmentData'])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('../sessionFiles.pickle', 'rb')\n",
    "allSessions = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "sessionDict = allSessions[0]\n",
    "sessionDict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'D:\\\\Github\\\\Interception_UXF_Analysis\\\\ValidationNotebooks'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Data/'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32md:\\Github\\Interception_UXF_Analysis\\ValidationNotebooks\\mergeSessions_1.ipynb Cell 4'\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      <a href='vscode-notebook-cell:/d%3A/Github/Interception_UXF_Analysis/ValidationNotebooks/mergeSessions_1.ipynb#ch0000010?line=0'>1</a>\u001B[0m \u001B[39m# Get folder/filenames\u001B[39;00m\n\u001B[0;32m      <a href='vscode-notebook-cell:/d%3A/Github/Interception_UXF_Analysis/ValidationNotebooks/mergeSessions_1.ipynb#ch0000010?line=1'>2</a>\u001B[0m dataFolderList \u001B[39m=\u001B[39m []\n\u001B[1;32m----> <a href='vscode-notebook-cell:/d%3A/Github/Interception_UXF_Analysis/ValidationNotebooks/mergeSessions_1.ipynb#ch0000010?line=2'>3</a>\u001B[0m [dataFolderList\u001B[39m.\u001B[39mappend(name) \u001B[39mfor\u001B[39;00m name \u001B[39min\u001B[39;00m os\u001B[39m.\u001B[39;49mlistdir(\u001B[39m\"\u001B[39;49m\u001B[39mData/\u001B[39;49m\u001B[39m\"\u001B[39;49m) \u001B[39mif\u001B[39;00m name[\u001B[39m0\u001B[39m] \u001B[39m!=\u001B[39m \u001B[39m'\u001B[39m\u001B[39m.\u001B[39m\u001B[39m'\u001B[39m]\n\u001B[0;32m      <a href='vscode-notebook-cell:/d%3A/Github/Interception_UXF_Analysis/ValidationNotebooks/mergeSessions_1.ipynb#ch0000010?line=4'>5</a>\u001B[0m dataFolderList\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'Data/'"
     ]
    }
   ],
   "source": [
    " # Get folder/filenames\n",
    "dataFolderList = []\n",
    "[dataFolderList.append(name) for name in os.listdir(\"Data/\") if name[0] != '.']\n",
    "\n",
    "dataFolderList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Get folder/filenames\n",
    "    dataFolderList = []\n",
    "    [dataFolderList.append(name) for name in os.listdir(\"Data/\") if name[0] != '.']\n",
    "\n",
    "    for i, name in enumerate(dataFolderList):\n",
    "            if i == subNum:\n",
    "                print('***> ' + str(i) + ': ' + name )\n",
    "            else:\n",
    "                print(str(i) + ': ' + name )\n",
    "    \n",
    "\n",
    "    dataParentFolder = \"Data/\" + dataFolderList[subNum]\n",
    "    dataSubFolderList = []\n",
    "    [dataSubFolderList.append(name) for name in os.listdir(dataParentFolder) if name[0] != '.']\n",
    "    dataFolder = dataParentFolder + '/' + dataSubFolderList[0] + '/'\n",
    "\n",
    "    logger.info('Processing session: ' + dataFolder)\n",
    "\n",
    "    # Try to load pickle if doNotLoad == False\n",
    "    picklePath = dataFolder + dataSubFolderList[0] + '.pickle'\n",
    "    from os import path\n",
    "    if( doNotLoad == False and path.exists(picklePath)):\n",
    "        \n",
    "        file = open(picklePath, 'rb')\n",
    "        sessionData = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        logger.info('Importing session dict from pickle.')\n",
    "        \n",
    "        return sessionData\n",
    "\n",
    "    logger.info('Compiling session dict from *.csv.')\n",
    "\n",
    "    # If not loading from pickle, create and populate dataframes\n",
    "    rawExpUnityDataDf = pd.DataFrame()\n",
    "    rawExpGazeDataDf = pd.DataFrame()\n",
    "    processedExpDataDf = pd.DataFrame()\n",
    "\n",
    "    rawCalibUnityDataDf = pd.DataFrame()\n",
    "    rawCalibGazeDataDf = pd.DataFrame()\n",
    "    processedCalibDataDf = pd.DataFrame()\n",
    "\n",
    "    trialData = pd.read_csv( dataFolder + '/trial_results.csv')\n",
    "\n",
    "    for trIdx, trialResults in trialData.iterrows():\n",
    "\n",
    "        trialDict = processTrial(dataFolder, trialResults,len(trialData))\n",
    "\n",
    "        def addToDF(targetDF,dfIn):\n",
    "\n",
    "            return pd.concat([targetDF, dfIn])\n",
    "\n",
    "            # if( targetDF.empty ):\n",
    "            #     return dfIn\n",
    "            # else:\n",
    "            #     # targetDF = targetDF.append(dfIn)\n",
    "            #     return pd.concat([targetDF, dfIn])\n",
    "\n",
    "        if (trialResults['trialType'] == 'interception'):\n",
    "\n",
    "            processedExpDataDf = addToDF(processedExpDataDf,trialDict['interpolatedData'])\n",
    "            rawExpUnityDataDf = addToDF(rawExpUnityDataDf,trialDict['rawUnityData'])\n",
    "            rawExpGazeDataDf = addToDF(rawExpGazeDataDf,trialDict['rawGazeData'])\n",
    "\n",
    "        elif(trialResults['trialType'] == 'CalibrationAssessment'):\n",
    "\n",
    "            processedCalibDataDf = addToDF(processedCalibDataDf,trialDict['interpolatedData'])\n",
    "            rawCalibUnityDataDf = addToDF(rawCalibUnityDataDf,trialDict['rawUnityData'])\n",
    "            rawCalibGazeDataDf = addToDF(rawCalibGazeDataDf,trialDict['rawGazeData'])\n",
    "\n",
    "    # Rename trialdata columns\n",
    "    trialData.rename(columns={\"session_num\":\"sessionNumber\",\"trial_num\":\"trialNumber\",\n",
    "        \"block_num\":\"blockNumber\",\"trial_num_in_block\":\"trialNumberInBlock\",\n",
    "        \"start_time\":\"startTime\",\"end_time\":\"endTime\"},inplace=True)\n",
    "\n",
    "    trDataFiles = [i for i in trialData.columns.to_list() if '_filename' in i] \n",
    "\n",
    "    # Convert to multiindex\n",
    "    newColList = [convertIndexToMultiIndexUsingUnderscore(c) for c in trialData.columns[:-len(trDataFiles)]]\n",
    "    newColList.extend([convertIndexToMultiIndexIgnoringUnderscore(c) for c in trialData.columns[-len(trDataFiles):]])\n",
    "    trialData.columns = pd.MultiIndex.from_tuples(newColList)\n",
    "    \n",
    "    expDict = json.load( open(dataFolder + '/settings/' + 'settings.json'))\n",
    "\n",
    "    processedExpDataDf = processedExpDataDf.reset_index(drop=True)\n",
    "    processedCalibDataDf = processedCalibDataDf.reset_index(drop=True)\n",
    "    \n",
    "    analysisParameters = json.load( open('analysisParameters.json'))\n",
    "    # analysisParameters['gazeDataConfidenceThreshold'] = gazeDataConfidenceThreshold\n",
    "\n",
    "    \n",
    "    #logger.warning('(**********************  SUBID FILE IS HARDCODED *******************************')\n",
    "    #subID = json.load( open(dataParentFolder + '/participantdetails/participant_details.csv'))['ppid']\n",
    "    subID = trialData['ppid'][1] \n",
    "\n",
    "    dictOut = {\"subID\": subID, \"trialInfo\": trialData.sort_index(axis=1),\"expConfig\": expDict,\n",
    "        \"rawExpUnity\": rawExpUnityDataDf.sort_index(axis=1), \"rawExpGaze\": rawExpGazeDataDf.sort_index(axis=1), \"processedExp\": processedExpDataDf.sort_index(axis=1),\n",
    "        \"rawCalibUnity\": rawCalibUnityDataDf.sort_index(axis=1), \"rawCalibGaze\": rawCalibGazeDataDf.sort_index(axis=1), \"processedCalib\": processedCalibDataDf.sort_index(axis=1),\n",
    "        \"analysisParameters\":analysisParameters}\n",
    "\n",
    "    with open(picklePath, 'wb') as handle:\n",
    "        pickle.dump(dictOut, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cae68830",
   "language": "python",
   "display_name": "PyCharm (Interception_UXF_Analysis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}